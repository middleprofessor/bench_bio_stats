# Preface {.unnumbered}

This book is an introduction to the statistical analysis of data from biological experiments with a focus on the estimation of treatment effects and measures of the uncertainty of theses estimates. Instead of a flowchart of "which statistical test", this book emphasizes a **regression modeling** approach using **linear models** and extensions of linear models.

"What what? I learned from the post-doc in my lab that regression was for data with a continuous independent variable and that *t*-tests and ANOVA were for data with categorical independent variables." No! This misconception has roots in the history of regression vs. ANOVA and is reinforced by how introductory biostatistics textbooks, and their instructors, *choose* to teach statistics.

Classical linear regression, *t*-tests and ANOVA are all special cases of a **linear model**. The different linear models in this text are all variations of the equation for a line $Y = mX + b$ using slightly different notation:

$$
\mathrm{E}(Y | X) = \beta_0 + \beta_1 X
$$ {#eq:index-regression-model}

The chapter [An introduction to linear models](#intro-linear-models) explains the meaning of this notation. Here, just recognize that this is a **regression model**, but in modern statistics, we use this to not only estimate the effects of a continuous $X$ variable on some response (classical regression) but also for the estimation of effects of a categorical treatment variable on some response (as in classical *t*-tests and ANOVA). A regression model with a categorical treatment variable is possible because the treatment variable is recoded into a numeric **indicator variable** indicating group membership ("wildtype" or "knockout"). Classical *t*-tests and ANOVA are equivalent to special cases of regression models but the linear model is usually presented in a different way, one that allows simple "paper and pencil math" (addition, subtraction, multiplication, division). The linear model underneath a classical *t*-tests/ANOVA is some variation of

$$
\overline{Y}_k = \mu + \alpha_k
$$ {#eq:index-anova-model}

where $\mu$ is the grand mean and $\alpha_k$ is the difference between the mean of treatment *k* and the grand mean.

In this text, I use **linear model** for any model that looks like Equation @eq:index-regression-model and **ANOVA model** for any model that looks like Equation @eq:index-anova-model (many statistics textbooks call these "cell-mean models"). It would be more correct to call models that look like Equation @eq:index-regression-model a **regression model** but the word "regression" has a lot of baggage because of how it is taught -- as a method for data with continuous $X$ ("independent") variables. If I said, "this is a book of regression models for analyzing your experimental data", you might quite reasonably, but incorrectly, assume that the book wasn't really relevant to your experiments because your independent variables are categorical ("WT" vs."KO") and not continuous.
